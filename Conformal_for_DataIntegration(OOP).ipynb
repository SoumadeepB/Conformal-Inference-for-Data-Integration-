{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4927e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli, uniform, expon, chi2, norm\n",
    "from scipy.optimize import fsolve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5898c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, N=200_000, nA=20_000, nB=500, seed=None):\n",
    "        \"\"\"\n",
    "        Initializes the data generator.\n",
    "\n",
    "        Parameters:\n",
    "        - N: Population size\n",
    "        - nA: Target size for non-probability sample\n",
    "        - nB: Target size for probability sample\n",
    "        - seed: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.nA = nA\n",
    "        self.nB = nB\n",
    "        self.seed = seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        \"\"\"\n",
    "        For this example covariate has been generated from N(0,1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.X1 = norm.rvs(0, 1, size=N) \n",
    "        self.epsilon = norm.rvs(0, 2, size=N)\n",
    "        self.Y = 2 + 3 * self.X1 + self.epsilon\n",
    "        self.gamma0 = None\n",
    "\n",
    "        self.pi_A = None\n",
    "        self.pi_B = None\n",
    "        self.SA = None\n",
    "        self.SB = None\n",
    "\n",
    "    def _solve_gamma0(self):\n",
    "        \"\"\"\n",
    "        Solves for gamma0 to achieve the target non-probability sample size. \n",
    "        Here \n",
    "        pi_a = 1 / (1 + np.exp(-(gamma0 + 0.5*((x1-4)**2))))\n",
    "        which ensures covariate shift.\n",
    "        \n",
    "        \"\"\"\n",
    "        def objective(gamma0):\n",
    "            pi = 1 / (1 + np.exp(-(gamma0 + 0.5*((self.X1-4)**2))))\n",
    "            return np.sum(pi) - self.nA\n",
    "\n",
    "        self.gamma0 = fsolve(objective, x0=0)[0]\n",
    "\n",
    "    def generate_samples(self):\n",
    "        \"\"\"\n",
    "        Generates the full population and draws non-probability and probability samples.\n",
    "        \"\"\"\n",
    "        self._solve_gamma0()\n",
    "\n",
    "        self.pi_A = 1 / (1 + np.exp(-(self.gamma0 + 0.5*((self.X1-4)**2))))\n",
    "        self.SA = np.random.uniform(size=self.N) < self.pi_A\n",
    "        self.c = fsolve(lambda c: np.max(c + 0.5*self.X1 + 0.03*self.Y) / np.min(c + 0.5*self.X1 + 0.03*self.Y) - 50, x0=1)[0]\n",
    "        self.pi_B = self.c + self.X1 + 0.03*self.Y\n",
    "        self.pi_B = (self.pi_B/sum(self.pi_B))*self.nB\n",
    "        self.SB = np.random.uniform(size=self.N) < (self.pi_B / np.sum(self.pi_B)) * self.nB\n",
    "\n",
    "    def get_population(self):\n",
    "        \"\"\"\n",
    "        Returns the full population dataframe.\n",
    "        \"\"\"\n",
    "        return pd.DataFrame({\n",
    "            'x1': self.X1,\n",
    "            'y': self.Y,\n",
    "            'pi_A': self.pi_A,\n",
    "            'pi_B': self.pi_B,\n",
    "            'SA': self.SA,\n",
    "            'SB': self.SB\n",
    "        })\n",
    "\n",
    "    def get_nonprob_sample(self):\n",
    "        \"\"\"\n",
    "        Returns the non-probability sample dataframe.\n",
    "        \"\"\"\n",
    "        pop = self.get_population()\n",
    "        return pop.loc[pop['SA'], ['y', 'x1']]\n",
    "\n",
    "    def get_prob_sample(self):\n",
    "        \"\"\"\n",
    "        Returns the probability sample dataframe.\n",
    "        \n",
    "        \"\"\"\n",
    "        pop = self.get_population()\n",
    "        return pop.loc[pop['SB'], ['y', 'x1', 'pi_B']]\n",
    "    \n",
    "    def get_gamma0(self):\n",
    "        \n",
    "        return(self.gamma0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918a50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformalRegressor:\n",
    "    \n",
    "    \"\"\"\n",
    "    ######################################################################\n",
    "    Conformal Regressor for predictive intervals under covariate shift.\n",
    "    ######################################################################\n",
    "    \n",
    "    Computes individual prediction intervals with confidence level alpha using the methodology \n",
    "    proposed by Tibshiranni et al. in \"Conformal Prediction Under Covariate Shift\". This also \n",
    "    involves local scoring by modelling the MAD using the same prediction model as used to model \n",
    "    the conditional distribution of the response given the covariates. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.05, random_state=420):\n",
    "        \"\"\"\n",
    "        Initialize conformal regressor with confidence level alpha and RNG seed\n",
    "        \n",
    "        \"\"\" \n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.model = RandomForestRegressor(random_state=random_state)  # Main prediction model\n",
    "        self.mad_model = RandomForestRegressor(random_state=random_state)  # Model to estimate residual spread (MAD)\n",
    "        self.q1 = None  # Quantile for equal weighting (used in unweighted baseline interval)\n",
    "\n",
    "    def fit(self, train_X, train_Y):\n",
    "        \n",
    "        \"\"\"\n",
    "        Fit both the primary model and the (MAD) model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_X : np.ndarray\n",
    "            Training covariates.\n",
    "        train_Y : np.ndarray\n",
    "            Training responses.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Fit the main model on training data\n",
    "        self.model.fit(train_X, train_Y)\n",
    "        # Fit a model to predict the absolute residuals (MAD model)\n",
    "        residuals = np.abs(self.model.predict(train_X) - train_Y)\n",
    "        self.mad_model.fit(train_X, residuals)\n",
    "\n",
    "    def _weighted_quantile(self, values, weights, alpha):\n",
    "        \n",
    "        \"\"\"\n",
    "        Compute weighted quantile.\n",
    "\n",
    "        Input:\n",
    "        ----------\n",
    "        values : array-like\n",
    "            Values to compute quantiles over.\n",
    "        weights : array-like\n",
    "            Corresponding weights.\n",
    "        alpha : float\n",
    "            Desired quantile level.\n",
    "\n",
    "        Output:\n",
    "        -------\n",
    "        float\n",
    "            The weighted quantile.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.DataFrame({'values': values, 'weights': weights})\n",
    "        df = df.sort_values('values')\n",
    "        df['cum_weight'] = df['weights'].cumsum() / df['weights'].sum()\n",
    "        return np.interp(alpha, df['cum_weight'], df['values'])\n",
    "\n",
    "    def calibrate(self, calib_X, calib_Y, calib_weights):\n",
    "        \"\"\"\n",
    "        Calibrate model using conformity scores and weights.\n",
    "\n",
    "        Input:\n",
    "        ----------\n",
    "        calib_X : np.ndarray\n",
    "             Calibration covariates.\n",
    "        calib_Y : np.ndarray\n",
    "             Calibration responses.\n",
    "        calib_weights : np.ndarray\n",
    "             Calibration weights \n",
    "        \"\"\"\n",
    "        \n",
    "        # Predict responses on calibration set\n",
    "        calib_y_pred = self.model.predict(calib_X)\n",
    "        # Compute conformity scores (absolute errors)\n",
    "        conformity_scores = np.abs(calib_Y - calib_y_pred)\n",
    "        # Predict local MADs for normalization\n",
    "        calib_mad = self.mad_model.predict(calib_X)\n",
    "        norm_scores = conformity_scores / calib_mad\n",
    "\n",
    "        # Save conformity scores and calibration weights\n",
    "        self.values_with_inf = np.append(norm_scores, np.inf)\n",
    "        self.weights = calib_weights\n",
    "\n",
    "        # Compute equal-weighted quantile (for no-covariate-shift baseline)\n",
    "        equal_weights = np.ones(len(calib_Y) + 1) / (len(calib_Y) + 1)\n",
    "        self.q_equal = self._weighted_quantile(self.values_with_inf, equal_weights, 1 - self.alpha)\n",
    "\n",
    "    def predict(self, test_X, test_weights):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generate prediction intervals for the unseen test data.\n",
    "\n",
    "        Input:\n",
    "        ----------\n",
    "        test_X : np.ndarray\n",
    "            Test covariates.\n",
    "        test_weights : np.ndarray\n",
    "            Test weights for conformal quantile adjustment.\n",
    "\n",
    "        Output:\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary containing prediction means and intervals (with and without covariate shift adjustment).\n",
    "        \"\"\"\n",
    "        \n",
    "        # Predict mean and MAD for test data\n",
    "        y_pred = self.model.predict(test_X)\n",
    "        mad_pred = self.mad_model.predict(test_X)\n",
    "\n",
    "        # Initialize prediction interval lists\n",
    "        lower = []\n",
    "        upper = []\n",
    "        lower_wo = []  # Without covariate shift adjustment\n",
    "        upper_wo = []\n",
    "\n",
    "        for i in range(len(test_X)):\n",
    "            # Append new test weight to calibration weights\n",
    "            weights_with_test = np.append(self.weights, test_weights[i])\n",
    "            # Normalize (optional: already handled in quantile function)\n",
    "            weights_with_test = weights_with_test / np.sum(weights_with_test)\n",
    "            # Get weighted quantile\n",
    "            q_weighted = self._weighted_quantile(self.values_with_inf, weights_with_test, 1 - self.alpha)\n",
    "\n",
    "            # Compute prediction intervals (covariate shift adjusted)\n",
    "            lower.append(y_pred[i] - q_weighted * mad_pred[i])\n",
    "            upper.append(y_pred[i] + q_weighted * mad_pred[i])\n",
    "\n",
    "            # Compute unweighted intervals (no shift correction)\n",
    "            lower_wo.append(y_pred[i] - self.q_equal * mad_pred[i])\n",
    "            upper_wo.append(y_pred[i] + self.q_equal * mad_pred[i])\n",
    "\n",
    "        return {\n",
    "            'pred': y_pred,\n",
    "            'lower': np.array(lower),\n",
    "            'upper': np.array(upper),\n",
    "            'lower_wo': np.array(lower_wo),\n",
    "            'upper_wo': np.array(upper_wo)\n",
    "        }\n",
    "\n",
    "    def evaluate(self, test_Y, lower, upper, lower_wo, upper_wo):\n",
    "        \"\"\"\n",
    "        Evaluate interval quality using empirical coverage and interval width.\n",
    "\n",
    "        Input:\n",
    "        ----------\n",
    "        test_Y : np.ndarray\n",
    "            True test responses.\n",
    "        lower : np.ndarray\n",
    "            Lower bounds of conformal intervals with covariate shift adjustment.\n",
    "        upper : np.ndarray\n",
    "            Upper bounds of conformal intervals with covariate shift adjustment.\n",
    "        lower_wo : np.ndarray\n",
    "            Lower bounds without covariate shift adjustment.\n",
    "        upper_wo : np.ndarray\n",
    "            Upper bounds without covariate shift adjustment.\n",
    "\n",
    "        Output:\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary of coverage and average width metrics.\n",
    "        \"\"\"\n",
    "        coverage = np.mean((test_Y >= lower) & (test_Y <= upper))\n",
    "        coverage_wo = np.mean((test_Y >= lower_wo) & (test_Y <= upper_wo))\n",
    "        width = np.mean(upper - lower)\n",
    "        width_wo = np.mean(upper_wo - lower_wo)\n",
    "        return {\n",
    "            'coverage': coverage,\n",
    "            'coverage_wo': coverage_wo,\n",
    "            'width': width,\n",
    "            'width_wo': width_wo\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c4d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(seed=123)\n",
    "gen.generate_samples()\n",
    "pop = gen.get_population()\n",
    "nonprob = gen.get_nonprob_sample()\n",
    "prob = gen.get_prob_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a746ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = nonprob[['x1']]\n",
    "train_Y = nonprob['y']\n",
    "val_X = prob[['x1']]\n",
    "val_Y = prob['y']\n",
    "calib_weights_val = 1/prob[['pi_B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22710b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformalRegressor(alpha=0.05)\n",
    "model.fit(train_X, train_Y)\n",
    "model.calibrate(val_X, val_Y, calib_weights_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80886c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma0 = gen.get_gamma0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "954c3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from population\n",
    "sampled_df = pop.sample(n=500, random_state=420)\n",
    "test_X = sampled_df[['x1']]\n",
    "test_Y = sampled_df['y']\n",
    "calib_weights_test = np.array(1 + np.exp(-(gamma0 + 0.5 * ((test_X - 4) ** 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f356e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = model.predict(test_X, calib_weights_test)\n",
    "eval_dict = model.evaluate(\n",
    "    test_Y,\n",
    "    lower=pred_dict['lower'],\n",
    "    upper=pred_dict['upper'],\n",
    "    lower_wo=pred_dict['lower_wo'],\n",
    "    upper_wo=pred_dict['upper_wo']\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
